---
title: "Simulating the bins: Analysis of Histogram Layout Differences Across Binwidths"
editor: source
format: 
  pdf:
    classoption: ["10pt", "english", "singlespacing", "headsepline"]
    geometry:
        - paper=letterpaper
        - inner=2.5cm
        - outer=3.8cm
        - bindingoffset=.5cm
        - top=0.75cm
        - bottom=0.75cm
        - left=1.75cm
        - right=1.75cm
---

```{r include_packages, include = FALSE}
library(GGally)
library(palmerpenguins)
library(tidyverse)
library(gridExtra)
library(ggpcp)
knitr::opts_chunk$set(fig.pos = "H", out.extra = "")

# Function to create a data frame for plotting with multiple binwidths
prepare_histogram_data <- function(data, binwidths) {
  do.call(rbind, lapply(binwidths, function(bw) {
    breaks <- seq(min(data) - bw, max(data) + bw, by = bw) # Extend the range
    hist <- hist(data, breaks = breaks, plot = FALSE)
    data.frame(
      x = hist$mids,
      count = hist$counts,
      binwidth_label = paste0("Binwidth: ", bw)
    )
  }))
}

# Function to plot faceted histograms with dynamic binwidth
plot_histogram_facet <- function(data, binwidths, title) {
  hist_data <- prepare_histogram_data(data, binwidths)
  
  ggplot(hist_data, aes(x, count)) +
    geom_bar(stat = "identity", fill = "blue", color = "blue", alpha = 0.7) +
    facet_wrap(~ binwidth_label, scales = "free_y") +
    labs(title = title, x = "Values", y = "Frequency") +
    theme_minimal() + coord_flip()
}

group_scale_color <-   function(...) scale_color_manual(
  "group", values = c("group1" = "#540D6E", "group2" = "#219B9D", "group3" = "#FF8000", ...)
)  

# Updated Solution #1
numerical_tie_breaker_solution1 <- function(values, tie_band = 0.05) {
  sorted_idx <- order(values)
  sorted_values <- values[sorted_idx]
  
  adjusted_sorted <- sorted_values
  for (i in seq_along(sorted_values)) {
    if (i > 1 && sorted_values[i] == sorted_values[i - 1]) {
      adjusted_sorted[i] <- adjusted_sorted[i - 1] + tie_band
    }
  }
  
  adjusted_values <- numeric(length(values))
  adjusted_values[sorted_idx] <- adjusted_sorted
  return(adjusted_values)
}


# Updated Solution #2: Dynamic tie band based on data properties
auto_fraction <- function(values, scale_factor = 0.1) {
  unique_vals <- unique(sort(values))
  diffs <- diff(unique_vals)
  
  # Keep only positive gaps
  positive_diffs <- diffs[diffs > 0]
  
  # If everything is identical or only one unique value, return a small default
  if (length(positive_diffs) == 0) {
    return(scale_factor)
  }
  
  # A robust choice: median of these positive gaps
  typical_gap <- median(positive_diffs)
  
  # Return a fraction that is a multiple of the median gap
  scale_factor * typical_gap
}


numerical_tie_breaker_solution2 <- function(values, base_fraction = 0.05) {
  is_whole_number <- all(abs(values - round(values)) < .Machine$double.eps^0.5)
  
  if (is_whole_number) {
    tie_band <- base_fraction
  } else {
    is_normal <- FALSE
    if (length(values) >= 3) {
      shapiro_p <- shapiro.test(values)$p.value
      is_normal <- (shapiro_p > 0.05)
    }
    
    q <- stats::quantile(values, probs = c(0.25, 0.75))
    iqr_value <- q[2] - q[1]
    lower_bound <- q[1] - 1.5 * iqr_value
    upper_bound <- q[2] + 1.5 * iqr_value
    has_outliers <- any(values < lower_bound) || any(values > upper_bound)
    
    if (is_normal && !has_outliers) {
      tie_band <- base_fraction * stats::sd(values)
    } else {
      tie_band <- base_fraction * iqr_value
    }
  }
  
  sorted_idx <- order(values)
  sorted_values <- values[sorted_idx]
  
  adjusted_sorted <- sorted_values
  for (i in seq_along(sorted_values)) {
    if (i > 1 && sorted_values[i] == sorted_values[i - 1]) {
      adjusted_sorted[i] <- adjusted_sorted[i - 1] + tie_band
    }
  }
  
  adjusted_values <- numeric(length(values))
  adjusted_values[sorted_idx] <- adjusted_sorted
  return(adjusted_values)
}


create_simulated_data_test <- function(data, data_type, tie_band_value = 0.05, 
                                       dodge_value = 0.01, scale_factor = 0.05){
  

# Create a data frame for visualization
df <- data.frame(
  ID = 1:n,
  original_whole = sort(round(data, 0)), 
  original_dec1 = sort(round(data, 1)), 
  original_dec2 = sort(round(data, 2)),
  # Original data with ties
  manual_tie_band = sort(numerical_tie_breaker_solution1(data, tie_band = tie_band_value)),
  auto_tie_band = sort(numerical_tie_breaker_solution2(data, 
                                                       base_fraction = auto_fraction(data, scale_factor = scale_factor))),
  group = sort(sample(c('group1', 'group2', 'group3'), n, replace=TRUE))
)

# df_pcp <- df %>%
#   pcp_select( group, original_dec1, manual_tie_band, group, original_dec1, auto_tie_band) %>%
#   pcp_scale() %>%
#   pcp_arrange(method = "from-both")

# Create the parallel coordinate plot using ggpcp
p1 <- df %>%
  pcp_select(group, original_dec1, group, manual_tie_band, group) %>%
  pcp_scale() %>%
  pcp_arrange(method = "from-both") %>%
  ggplot(aes_pcp()) +
  geom_pcp_boxes() +  # Add boxes for each variable
  geom_pcp(aes(colour = group), overplot = "none", alpha = 0.5) +  # Add lines for each data point, colored by Type
  geom_pcp_labels() +  # Add labels for each variable
  theme_pcp() +  # Use the default theme for PCP
  geom_point(aes(colour = group), size = 0.75, position = position_dodge(dodge_value)) +
  labs(
    title = "PCP: Original vs Manual Tie-band Adjusted",
    subtitle = paste("(Simulated", data_type,  "Data)", sep = ' '),
    x = "Variables",
    y = "Scaled Values"
  ) + theme(legend.position = "none") + 
  #guides(color = F) + 
  group_scale_color() + 
  guides(color = guide_legend(title = "Data Type"))  # Add a legend for the Type variable

p2 <- df %>%
  pcp_select(group, original_dec1, group, auto_tie_band, group) %>%
  pcp_scale() %>%
  pcp_arrange(method = "from-both") %>%
  ggplot(aes_pcp()) +
  geom_pcp_boxes() +  # Add boxes for each variable
  geom_pcp(aes(colour = group), overplot = "none", alpha = 0.5) +  # Add lines for each data point, colored by Type
  geom_pcp_labels() +  # Add labels for each variable
  theme_pcp() +  # Use the default theme for PCP
  geom_point(aes(colour = group), size = 0.75, position = position_dodge(dodge_value)) +
  labs(
    title = "PCP: Original vs Auto Tie-band Adjusted",
    subtitle = paste("(Simulated", data_type,  "Data)", sep = ' '),
    x = "Variables",
    y = "Scaled Values"
  ) + theme(legend.position = "none") + 
  #guides(color = F) + 
  group_scale_color() + 
  guides(color = guide_legend(title = "Data Type"))  # Add a legend for the Type variable
return(grid.arrange(p1, p2, ncol = 2))

}

```


# Point Mass Distribution:


```{r point_mass}
#| out-width: 100%
simulate_point_mass <- function(n, value) {
  rep(value, n)
}

# Simulate data
set.seed(42) # Set seed for reproducibility
n <- 100

point_mass_data <- simulate_point_mass(n, round(n/12, 0))

create_simulated_data_test(point_mass_data, "Point Mass")

```

# Exponential Distribution:

- Simulated data follows an exponential decay pattern.


```{r exponential}
#| out-width: 100%
# Function to simulate exponential distribution
simulate_exponential <- function(n, rate) {
  rexp(n, rate = rate)
}

exponential_data <- simulate_exponential(n, rate = .33)

create_simulated_data_test(exponential_data, "Exponential")

```

# Normal Distribution:

- Simulated data is centered around a mean (10) with a specified standard deviation (3).


```{r normal}
#| out-width: 100%
# Function to simulate normal distribution
simulate_normal <- function(n, mean, sd) {
  rnorm(n, mean = mean, sd = sd)
}

normal_data <- simulate_normal(n, mean = 10, sd = 3)

create_simulated_data_test(normal_data, "Normal")
```

# Poisson Distribution:

- Simulated count data with a mean occurrence (lambda = 3).


```{r poisson}
#| out-width: 100%
# Function to simulate Poisson distribution
simulate_poisson <- function(n, lambda) {
  rpois(n, lambda = lambda)
}

poisson_data <- simulate_poisson(n, lambda = 3)

create_simulated_data_test(poisson_data, "Poisson")
```


# Uniform Distribution:

- Simulated data is evenly distributed between a minimum (0) and maximum (1).


```{r uniform}
#| out-width: 100%
# Function to simulate Uniform distribution
simulate_uniform <- function(n, min, max) {
  runif(n, min = min, max = max)
}

uniform_data <- simulate_uniform(n, min = 0, max = 1)

create_simulated_data_test(uniform_data, "Uniform")
```

# Binomial Distribution:

- Models the number of successes in a fixed number of trials (size = 10, prob = 0.5).

```{r binomial}
#| out-width: 100%
# Function to simulate binomial distribution
simulate_binomial <- function(n, size, prob) {
  rbinom(n, size = size, prob = prob)
}

binomial_data <- simulate_binomial(n, size = 20, prob = 0.5)

create_simulated_data_test(binomial_data, "Binomial")

```

# Beta Distribution:

- Continuous data bounded between 0 and 1, modeled with shape parameters (shape1 = 2, shape2 = 5).

```{r beta}
#| out-width: 100%
# Function to simulate beta distribution
simulate_beta <- function(n, shape1, shape2) {
  rbeta(n, shape1 = shape1, shape2 = shape2)
}

beta_data <- simulate_beta(n, shape1 = 2, shape2 = 5)

create_simulated_data_test(beta_data, "Beta")

```

# Gamma Distribution:

- Models waiting times with shape and rate parameters (shape = 2, rate = 1).

```{r gamma}
#| out-width: 100%
# Function to simulate gamma distribution
simulate_gamma <- function(n, shape, rate) {
  rgamma(n, shape = shape, rate = rate)
}

gamma_data <- simulate_gamma(n, shape = 2, rate = 1)

create_simulated_data_test(gamma_data, "Gamma")

```

# Chi-Square Distribution:

- Data follows a chi-square distribution with degrees of freedom (df = 3).

```{r chi_square}
#| out-width: 100%
# Function to simulate chi-square distribution
simulate_chisquare <- function(n, df) {
  rchisq(n, df = df)
}

chisquare_data <- simulate_chisquare(n, df = 3)

create_simulated_data_test(chisquare_data, "Chi-Square")

```

# Negative Binomial Distribution:

- Models the number of failures before achieving a set number of successes.

```{r negative_bin}
#| out-width: 100%
# Function to simulate negative binomial distribution
simulate_negative_binomial <- function(n, size, prob) {
  rnbinom(n, size = size, prob = prob)
}

negative_binomial_data <- simulate_negative_binomial(n, size = 10, prob = 0.3)

create_simulated_data_test(negative_binomial_data, "Negative Binomial")

```

# Log-Normal Distribution:

- Data is distributed such that the logarithm of the values follows a normal distribution (meanlog = 0, sdlog = 1).

```{r lognormal}
#| out-width: 100%
# Function to simulate log-normal distribution
simulate_lognormal <- function(n, meanlog, sdlog) {
  rlnorm(n, meanlog = meanlog, sdlog = sdlog)
}

lognormal_data <- simulate_lognormal(n, meanlog = 0, sdlog = 1)

create_simulated_data_test(lognormal_data, "Log-normal")

```

<!-- # Cauchy Distribution: -->

<!-- - A heavy-tailed distribution (location = 0, scale = 1). -->

<!-- - Histograms demonstrate extreme variability, with very large positive and negative values for different binwidths. -->

<!-- ```{r cauchy} -->
<!-- # Function to simulate Cauchy distribution -->
<!-- simulate_cauchy <- function(n, location, scale) { -->
<!--   rcauchy(n, location = location, scale = scale) -->
<!-- } -->

<!-- cauchy_data <- simulate_cauchy(n, location = 0, scale = 1) -->

<!-- plot_histogram_facet(cauchy_data, binwidths, "Cauchy Distribution") -->

<!-- ``` -->

